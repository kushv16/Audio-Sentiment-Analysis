You can find the project report: [here](https://drive.google.com/file/d/1p0d1a6O0wo_gb9hHn4yem3OGHlQe34Ub/view?usp=share_link)

# Abstract

Automating the evaluation process is necessary for achieving objectivity when judging the performance of executives working in call centers. We have been working on constructing a system that employs Audio Sentiment Analysis to analyze call records and provides intelligent graded emotions by utilizing Machine Learning and Deep Learning. In order to train and evaluate the performance of the proposed system, we pooled data from six different datasets. The models developed in the presented work were trained on a total of 89 features. The VGGish network was the best performing model with an accuracy of 94% during training, 87% during validation, and 84% during testing. The recorded call audio files are processed and diarized into its respective speakers. The chunks obtained of the respective speaker were then passed to the model to predict the overall sentiment of the audio clip. The trained system is specific to analyzing call recordings, diarizing speakers to understand individual emotions and weighing them in accordance to the entire call to evaluate the final emotions, which is important to rate an employee's performance.
